<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Comparing supervised machine learning algorithms in classifying wine quality</title>

<script src="site_libs/header-attrs-2.19/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link rel="apple-touch-icon" sizes="57x57" href="icons/apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="icons/apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="icons/apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="icons/apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="icons/apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="icons/apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="icons/apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="icons/apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="icons/apple-icon-180x180.png">
<link rel="icon" type="image/png" sizes="192x192"  href="icons/android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="icons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="icons/favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="icons/favicon-16x16.png">
<link rel="manifest" href="manifest.json">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="icons/ms-icon-144x144.png">
<meta name="theme-color" content="#ffffff">

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>



<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #232629;
    color: #7a7c7d;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #7a7c7d;  padding-left: 4px; }
div.sourceCode
  { color: #cfcfc2; background-color: #232629; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span { color: #cfcfc2; } /* Normal */
code span.al { color: #95da4c; background-color: #4d1f24; font-weight: bold; } /* Alert */
code span.an { color: #3f8058; } /* Annotation */
code span.at { color: #2980b9; } /* Attribute */
code span.bn { color: #f67400; } /* BaseN */
code span.bu { color: #7f8c8d; } /* BuiltIn */
code span.cf { color: #fdbc4b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #3daee9; } /* Char */
code span.cn { color: #27aeae; font-weight: bold; } /* Constant */
code span.co { color: #7a7c7d; } /* Comment */
code span.cv { color: #7f8c8d; } /* CommentVar */
code span.do { color: #a43340; } /* Documentation */
code span.dt { color: #2980b9; } /* DataType */
code span.dv { color: #f67400; } /* DecVal */
code span.er { color: #da4453; text-decoration: underline; } /* Error */
code span.ex { color: #0099ff; font-weight: bold; } /* Extension */
code span.fl { color: #f67400; } /* Float */
code span.fu { color: #8e44ad; } /* Function */
code span.im { color: #27ae60; } /* Import */
code span.in { color: #c45b00; } /* Information */
code span.kw { color: #cfcfc2; font-weight: bold; } /* Keyword */
code span.op { color: #cfcfc2; } /* Operator */
code span.ot { color: #27ae60; } /* Other */
code span.pp { color: #27ae60; } /* Preprocessor */
code span.re { color: #2980b9; background-color: #153042; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #da4453; } /* SpecialString */
code span.st { color: #f44f4f; } /* String */
code span.va { color: #27aeae; } /* Variable */
code span.vs { color: #da4453; } /* VerbatimString */
code span.wa { color: #da4453; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Home</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="about_me.html">About Me</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Portfolio
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="matern-spatial.html">Spatial modeling of school gun violence</a>
    </li>
    <li>
      <a href="ergm_models.html">Sexual network exponential random graph modeling</a>
    </li>
    <li>
      <a href="wine-classification.html">Classifying wine quality</a>
    </li>
    <li>
      <a href="bitcoin.html">Forecasting bitcoin value</a>
    </li>
    <li>
      <a href="housing-prices.html">Predicting housing prices</a>
    </li>
    <li>
      <a href="https://pinchunchen.shinyapps.io/ggomoku/">Play Gomoku using Shiny</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Contact Me
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="mailto:jsteven.raquel8@gmail.com">jsteven.raquel8@gmail.com</a>
    </li>
    <li>
      <a href="https://github.com/jstevenr">GitHub</a>
    </li>
    <li>
      <a href="https://www.linkedin.com/in/jstevenr/">LinkedIn</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Comparing supervised machine learning
algorithms in classifying wine quality</h1>

</div>


<p>This paper was originally written as a final project for PSTAT 131
Data Mining at UC Santa Barbara in spring 2017. It was revised heavily
for STATS 295 Advanced R at UC Irvine. A version of this project written
in Python can be found on my GitHub <a
href="https://github.com/jstevenr/wine-classification-python/blob/master/wine-quality.ipynb">here</a>.</p>
<hr />
<div id="abstract" class="section level1">
<h1>Abstract</h1>
<p>There are many different machine learning techniques useful for
classification. This paper compares various supervised learning
algorithms, namely decision trees, k-nearest neighbors, and random
forest in order to determine which is the most effective for binary
classification. The usefulness of cross-validation and the necessity of
randomness to ensure robustness is also discussed in this paper. We
utilize a free and openly sourced dataset available on the UC Irvine
Machine Learning Repository which includes several different attributes
of wine including alcohol content, sulfur dioxide, and acidity, among
others, and use these different ML algorithms to classify each of them
as either good or bad. We found that the models that performed the best
overall were random forest, but acknowledge that they suffer from a lack
of interpretability on account of being a black-box algorithm.</p>
</div>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>The importance of identifying what constitutes wine quality is a
question of interest to many; whether you produce wine or consume it.
While wine tasting as a profession has a long history, the application
of statistics and machine learning to determine wine quality is
comparatively much younger. Taking a dataset that has pre-existing
quality scores assigned to different wines, we can apply supervised
learning machine learning algorithms to attempt to determine which among
them performs best when classifying the quality of the wine, and what
attributes they determined were the most relevant in that
classification.</p>
</div>
<div id="background" class="section level1">
<h1>Background</h1>
<p>We use this white wine quality dataset, and all of its attributes
(e.g. sulfur dioxide content, pH) to determine what constitutes a “good”
(or above average) quality wine. We used the R statistical computing
language to conduct the analyses in this report. The data were found on
the UC Irvine Machine Learning Repository <span
class="citation">(<span>“<span>UCI</span> <span>Machine</span>
<span>Learning</span> <span>Repository</span>”</span> n.d.)</span>.</p>
<p>Knowing what makes a good wine was an interesting question because it
allows us to look at “taste” in a different way–without formal training
in wine tasting, we can determine algorithmically how and why a wine is
good using machine learning.</p>
<p>We utilized random forest, decision trees, and k-nearest neighbors to
classify each observation as either good or bad based off of these
attributes, while varying the number of variables, nodes, and number of
neighbors and comparing within and between these methods.</p>
<p>In this report, we find the accuracy, error rates, and area under the
ROC curve (AUC) of each of the three methods and ultimately came to
determine that random forest was the most effective in terms of accuracy
and AUC. It works well as a generalization of the decision tree method,
and as an algorithm it is robust, but it falls short in terms of
interpretability. kNN on the other hand is slow to compute with a
dataset of this dimensionality, as well as weaker in its accuracy both
in absolute terms and relative to the other methods we have tested
here.</p>
</div>
<div id="methods" class="section level1">
<h1>Methods</h1>
<p>First we can look at the correlation matrix of the dataset, to see if
any predictors are highly correlated with one another. We may have to
take out these predictors in order to avoid multicollinearity, which can
invalidate results. Having said this, multicollinearity is less of an
issue with decision trees, and even less so with random forest, both of
which are going to be used in this analysis. See Figure
@ref(fig:correlation-matrix) for the correlation matrix.</p>
<div class="figure">
<img src="wine-classification_files/figure-html/correlation-matrix-1.png" alt="The full correlation matrix of the data." width="672" />
<p class="caption">
The full correlation matrix of the data.
</p>
</div>
<p>Taking a look at the correlation coefficients <span
class="math inline">\(r\)</span> for the predictor variables, we see
that <code>density</code> is strongly correlated with
<code>residual.sugar</code> (<span class="math inline">\(r =
0.84\)</span>) and <code>alcohol</code> (<span class="math inline">\(r =
-0.78\)</span>), and moderately correlated with
<code>total.sulfur.dioxide</code> (<span class="math inline">\(r =
0.53\)</span>). <code>free.sulfur.dioxide</code> and
<code>total.sulfur.dioxide</code> are also moderately correlated with
each other (<span class="math inline">\(r = 0.62\)</span>) although this
is trivially known because of course, free sulfur dioxide is
incorporated into the total sulfur dioxide.</p>
<p>Aside from that correlations are all very low, including (and
especially) <code>quality</code>, the response variable, with the
predictors.</p>
<p>So, we should actually remove the variables
<code>residual.sugar</code> and <code>density</code>, as well as
<code>total.sulfur.dioxide</code> because if its direct relationship
with <code>free.sulfur.dioxide</code>, in order to address problems with
multi-collinearity. We’re going to withhold removing
<code>alcohol</code>, to see the if the initial effect of removing just
these three correlated variables is enough to address the issue. Then
we’ll show a new correlation matrix. See Figure
@ref(fig:correlation-matrix2).</p>
<div class="figure">
<img src="wine-classification_files/figure-html/correlation-matrix2-1.png" alt="The correlation matrix without residual sugar, density, or total sulfur dioxide." width="672" />
<p class="caption">
The correlation matrix without residual sugar, density, or total sulfur
dioxide.
</p>
</div>
<p>From the new correlation matrix it appears that none of the
predictors now have too high or a correlation with each other, and we
can decide that multi-collinearity is no longer an issue.</p>
<p>From here on out, we’re also going to want to convert the
<code>quality</code> response variable into a binary factor so that we
can use the predictors to classify the observations. We’re going to do
this by labeling all of the observations that have received an above
average (5 out of 10) as “good”, and the rest as “bad”, “bad” really
meaning “not good”.</p>
<p>It’s important to note that all of these numeric predictor variables
(<code>fixed.acidity</code>, <code>volatile.acidity</code>,
<code>citric.acid</code>, <code>chlorides</code>,
<code>free.sulfur.dioxide</code>, <code>pH</code>,
<code>sulphates</code>, <code>alcohol</code>) are not all scaled the
same. As such, it’s appropriate to scale them before running any further
analyses.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># to circumvent the issue of scale() changing to a matrix</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>scale_this <span class="ot">&lt;-</span> <span class="cf">function</span>(x) <span class="fu">as.vector</span>(<span class="fu">scale</span>(x))</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># scaling the 8 numeric attributes</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>white_sc <span class="ot">&lt;-</span> white2 <span class="sc">%&gt;%</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate_at</span>(<span class="fu">vars</span>(<span class="sc">-</span>quality), <span class="at">.funs =</span> scale_this</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Converting quality into a binary factor</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>white_sc <span class="ot">&lt;-</span> white_sc <span class="sc">%&gt;%</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate_at</span>(<span class="fu">vars</span>(quality), <span class="sc">~</span> <span class="fu">ifelse</span>(quality <span class="sc">&gt;</span> <span class="dv">5</span>, <span class="at">yes =</span> <span class="st">&quot;good&quot;</span>, </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">no =</span> <span class="st">&quot;bad&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate_at</span>(<span class="fu">vars</span>(quality), <span class="sc">~</span> <span class="fu">factor</span>(quality, </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;bad&quot;</span>, <span class="st">&quot;good&quot;</span>)))</span></code></pre></div>
<p>Now we have 8 numeric predictor variables, and one two-level
categorical variable (<code>quality</code>). We’re going to apply a few
different classification methods in order to firstly determine which the
best model for predicting is in terms of the relevant variables, and
secondly to find the best classification algorithm for this data.</p>
<p>In order to apply machine learning algorithms to this dataset, we
need to stratify the dataset into a training set and a test set. The
first set will be used to teach the classification model how to predict,
depending on the algorithm chosen. We then apply the algorithm to the
test set, and see how accurate the classification was.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># using a subset of 1000 obs for the training set</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">10</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>test_indices <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(white_sc), <span class="dv">1000</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> white_sc <span class="sc">%&gt;%</span> <span class="fu">slice</span>(test_indices)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> white_sc <span class="sc">%&gt;%</span> <span class="fu">slice</span>(<span class="sc">-</span>test_indices)</span></code></pre></div>
<div id="decision-tree" class="section level2">
<h2>Decision Tree</h2>
<p>The first method we are going to perform on this dataset, is Decision
Trees. Decision tree is a non-parametric classification method, which
uses a set of rules to predict that each observation belongs to the most
commonly occurring class label of training data [tan_introduction_2019].
We’re going to build these models using the <code>rpart</code> package
in R <span class="citation">(Therneau and Atkinson 2019)</span>.</p>
<p>Of course, we’re going to use <code>quality</code> as a response
variable, and each of the now 8 remaining numeric attributes as
predictors.</p>
<div id="repeated-k-fold-cross-validation-and-pruning"
class="section level3">
<h3>Repeated k-fold Cross Validation and Pruning</h3>
<p>We can use k-fold cross-validation, which randomly partitions the
dataset into folds of similar size, to see if the tree requires any
pruning which can improve the model’s accuracy as well as make it more
interpretable for us.</p>
<p>In k-fold cross validation, we divide the sample into <code>k</code>
sub samples, then train the model on <code>k-1</code> samples, leaving
one as a holdout sample. We compute validation error on each of these
samples, then average the validation error of all of them.</p>
<p>The idea of cross-validation is that it will sample multiple times
from the training set, with different separations. Ultimately, this
creates a more robust model i.e. the tree will not be overfit.</p>
<p>We can further optimize and reduce overfitting by doing repeated
k-fold cross validation which replicates the procedure multiple times
and reports the mean performance across all folds and repeats.
Overfitting refers to when a model is trained such that it can “predict”
labels extremely well for the training data but very poorly for any data
it hasn’t yet seen, such as a test set or even brand new data. There are
two kinds of errors committed by a classification model: training errors
and generalization errors <span class="citation">(Tan et al.
2019)</span>. The former refers to misclassification on the training
data while the later refers to misclassification on unseen data (such as
the test data). Ideally we would like to minimize both.</p>
<p>Cross validation will help us find the optimal complexity value for
the tree that yields the best accuracy while also being extremely
robust. This method using the <code>caret</code> <span
class="citation">(Kuhn 2020)</span> package finds the optimal complexity
parameter (“<code>cp</code>”) for tuning and prunes the tree
accordingly.</p>
<p>Generally speaking, un-pruned decision trees that do not leverage
cross-validation are prone to overfitting because they lack the element
of randomness and also being overly complex. By building the model by
using cross-validation to optimize the complexity parameter which
determines the size of the tree, while also doing repeated random
samples on the training data, we can end up with a simple, yet optimized
tree that is robust and less prone to overfitting. See Figure
@ref(fig:decision-tree-plot) for the decision tree plot.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># library(rpart) and library(caret) are loaded</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 10-fold cross validation repeated 3 times</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">10</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>caret_control <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;repeatedcv&quot;</span>, </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>                              <span class="at">number =</span> <span class="dv">10</span>, <span class="at">repeats =</span> <span class="dv">3</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Training the rpart decision tree based on the repeated cross-validation</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># library(e1071) is loaded</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>tree_cv <span class="ot">&lt;-</span> <span class="fu">train</span>(quality <span class="sc">~</span> .,</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> train,</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;rpart&quot;</span>,</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">trControl =</span> caret_control</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="co"># storing final model</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>tree <span class="ot">&lt;-</span> tree_cv<span class="sc">$</span>finalModel</span></code></pre></div>
<div class="figure">
<img src="wine-classification_files/figure-html/decision-tree-plot-1.png" alt="Decision tree built using rpart and 10-fold repeated cross-validation 3 times." width="672" />
<p class="caption">
Decision tree built using rpart and 10-fold repeated cross-validation 3
times.
</p>
</div>
<p>We can see while looking at the tree how often <code>alcohol</code>
appears and intuit from that that the amount of alcohol, whether high or
low, plays at least some part in the model’s classification of a good
wine. We also notice that the variables actually used in the
construction of the tree were <code>alcohol</code>,
<code>free.sulfur.dioxide</code>, and <code>volatile.acidity</code>.
It’s notable that this decision tree doesn’t have many “leaves” because
we used the optimal complexity parameter that came from the repeated
cross-validation step.</p>
<p>We can build a confusion matrix after using the data to predict on
the test set, and then find the accuracy rate and the error rate. The
confusion matrix is depicted as Table
@ref(tab:tree-confusion-matrix).</p>
<p>As an alternative metric to quantify the robustness of this method,
we can use the Receiver Operating Characteristic (ROC) curve and the
area underneath it (AUC). The ROC curve plots the false positive rate
against the true positive rate, and the area underneath it falls between
either 0.5 or 1, 0.5 being the worst (random classification), and 1
being the best (perfect classification). We can build the ROC curve and
calculate the area underneath it using the <code>ROCR</code> package in
R <span class="citation">(Sing et al. 2020)</span>.</p>
<p>The Table @ref(tab:records-1) shows the accuracy and error rate as
well as AUC for the decision tree model we have built. The ROC curve
itself can be seen in Figure @ref(fig:tree-ROC-curve).</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># a function that returns the accuracy of a confusion matrix</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>class_acc <span class="ot">&lt;-</span> <span class="cf">function</span>(conf) {</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sum</span>(<span class="fu">diag</span>(conf)) <span class="sc">/</span> <span class="fu">sum</span>(conf)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>tree_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(tree, test, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co"># confusion matrix</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>tree_conf <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="at">pred =</span> tree_pred, <span class="at">true =</span> test<span class="sc">$</span>quality)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co"># the class_acc() function is defined locally</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>tree_acc <span class="ot">&lt;-</span> <span class="fu">class_acc</span>(tree_conf)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="co"># misclassification error</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>tree_err <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> tree_acc</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="co"># library(ROCR is loaded)</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="co"># getting matrix of predicted class probabilities</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>all_tree_probs <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">predict</span>(tree, test, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>))</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>tree_probs <span class="ot">&lt;-</span> all_tree_probs[, <span class="dv">2</span>]</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>tree_roc_pred <span class="ot">&lt;-</span> <span class="fu">prediction</span>(tree_probs, test<span class="sc">$</span>quality)</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>tree_roc_perf <span class="ot">&lt;-</span> <span class="fu">performance</span>(tree_roc_pred, <span class="st">&quot;tpr&quot;</span>, <span class="st">&quot;fpr&quot;</span>)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Area under the curve</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>tree_auc_perf <span class="ot">&lt;-</span> <span class="fu">performance</span>(tree_roc_pred, <span class="st">&quot;auc&quot;</span>)</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>tree_auc <span class="ot">&lt;-</span> <span class="fu">round</span>(tree_auc_perf<span class="sc">@</span>y.values[[<span class="dv">1</span>]], <span class="dv">3</span>)</span></code></pre></div>
<table>
<caption>
Confusion matrix for decision tree.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
bad
</th>
<th style="text-align:right;">
good
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
bad
</td>
<td style="text-align:right;">
229
</td>
<td style="text-align:right;">
132
</td>
</tr>
<tr>
<td style="text-align:left;">
good
</td>
<td style="text-align:right;">
129
</td>
<td style="text-align:right;">
510
</td>
</tr>
</tbody>
</table>
<div class="figure">
<img src="wine-classification_files/figure-html/tree-ROC-curve-1.png" alt="ROC curve of the decision tree model." width="672" />
<p class="caption">
ROC curve of the decision tree model.
</p>
</div>
<table>
<caption>
Matrix with accuracy rates and AUCs for decision trees.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Accuracy Rate
</th>
<th style="text-align:right;">
Error Rate
</th>
<th style="text-align:right;">
AUC
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Repeated Cross-Validated Decision Tree
</td>
<td style="text-align:right;">
0.739
</td>
<td style="text-align:right;">
0.261
</td>
<td style="text-align:right;">
0.746
</td>
</tr>
<tr>
<td style="text-align:left;">
k=10 k-Nearest Neighbors
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
k=35 k-Nearest Neighbors
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
full Random Forest
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
small Random Forest
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
</tr>
</tbody>
</table>
<p>With an accuracy rate of <code>0.739</code>, this decision tree model
is not superb, but will still classify correctly about 3 out of 4 times.
The area under the ROC curve is about 0.746, which is halfway between
randomness (0) and a perfect model (1), showing a rather mediocre model.
A perfect right angle in the upper left would indicate a perfect model
and an AUC of 1, and a diagonal (as shown in the plot) depicts an AUC of
0.5, indicating an equal chance of a false positive and a true
positive.</p>
<p>Having appraised this decision tree model by its accuracy rate, error
rate, and AUC, we can now we can proceed to the next method of
classification.</p>
</div>
</div>
<div id="k-nearest-neighbors-knn" class="section level2">
<h2>k-Nearest Neighbors (kNN)</h2>
<p>We’re now going to apply the k-nearest neighbors method of
classification, which is a non-parametric method. k-Nearest neighbors
(or kNN) is called a “lazy learning” technique because it goes through
the training set every time it predicts a test sample’s quality <span
class="citation">(Tan et al. 2019)</span>. It finds this quality by
plotting the test sample in the same dimensional space as the training
data, then classifies it based on the “k nearest neighbor(s)”, i.e. if k
= 10, then the quality of the 10 nearest neighbors in the training data
to the test data observation will be applied to that observation. We’re
going to fit this model using the <code>class</code> package in R <span
class="citation">(Ripley 2020)</span>.</p>
<p>Distance is measured in different ways, but by default the
<code>knn()</code> function utilizes Euclidean distance.</p>
<p>This is rather problematic because when calculating distance it’s
assumed that attributes have the same effect, while this is not
generally true. So the distance metric (Euclidean distance in this case)
does not take into account the attributes’ relationships with each
other, which can result in misclassification. So already we have
determined a shortcoming in the kNN method before we have even applied
it. Although of course, we already dropped the predictors that were
highly correlated with each other, and what’s more we scaled the
remaining numeric predictors, which goes in a small way to addressing
this.</p>
<p>We’ll build a preliminary model using k = 10, calculate the accuracy
and error rates as well as the AUC, and compare them with the previous
model we build using decision trees. The confusion matrix for the model
is in Table @ref(tab:knn-confusion-matrix). The comparison between this
model and the decision tree model can be seen in Table
@ref(tab:records-2). The ROC curve itself can be seen in Figure
@ref(fig:knn-roc-curve).</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># library(class) is loaded</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co"># using 10 nearest neighbors</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">10</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>knn_pred <span class="ot">&lt;-</span> <span class="fu">knn</span>(</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">train =</span> train[, <span class="sc">-</span><span class="dv">9</span>],</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">test =</span> test[, <span class="sc">-</span><span class="dv">9</span>],</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">cl =</span> train<span class="sc">$</span>quality,</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">k =</span> <span class="dv">10</span>,</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">prob =</span> T</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co"># confusion matrix</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>knn_conf <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="at">pred =</span> knn_pred, <span class="at">true =</span> test<span class="sc">$</span>quality)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="co"># accuracy</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>knn_acc <span class="ot">&lt;-</span> <span class="fu">class_acc</span>(knn_conf)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co"># misclassification error</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>knn_err <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> knn_acc</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating the ROC curve for knn</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>knn_prob <span class="ot">&lt;-</span> <span class="fu">attr</span>(knn_pred, <span class="st">&quot;prob&quot;</span>)</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>knn_prob <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">ifelse</span>(knn_pred <span class="sc">==</span> <span class="st">&quot;-1&quot;</span>, <span class="dv">1</span> <span class="sc">-</span> knn_prob, knn_prob) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>knn_roc_pred <span class="ot">&lt;-</span> <span class="fu">prediction</span>(<span class="at">predictions =</span> knn_prob, <span class="at">labels =</span> test<span class="sc">$</span>quality)</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>knn_roc_perf <span class="ot">&lt;-</span> <span class="fu">performance</span>(knn_roc_pred,</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>  <span class="at">measure =</span> <span class="st">&quot;tpr&quot;</span>, <span class="at">x.measure =</span> <span class="st">&quot;fpr&quot;</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Area under the knn curve</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>knn_auc_perf <span class="ot">&lt;-</span> <span class="fu">performance</span>(knn_roc_pred, <span class="at">measure =</span> <span class="st">&quot;auc&quot;</span>)</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>knn_auc <span class="ot">&lt;-</span> <span class="fu">round</span>(knn_auc_perf<span class="sc">@</span>y.values[[<span class="dv">1</span>]], <span class="dv">3</span>)</span></code></pre></div>
<table>
<caption>
Confusion matrix for 10-nearest neighbors model.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
bad
</th>
<th style="text-align:right;">
good
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
bad
</td>
<td style="text-align:right;">
205
</td>
<td style="text-align:right;">
91
</td>
</tr>
<tr>
<td style="text-align:left;">
good
</td>
<td style="text-align:right;">
153
</td>
<td style="text-align:right;">
551
</td>
</tr>
</tbody>
</table>
<table>
<caption>
Matrix with accuracy rates and AUCs for decision trees and k-nearest
neighbors.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Accuracy Rate
</th>
<th style="text-align:right;">
Error Rate
</th>
<th style="text-align:right;">
AUC
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Repeated Cross-Validated Decision Tree
</td>
<td style="text-align:right;">
0.739
</td>
<td style="text-align:right;">
0.261
</td>
<td style="text-align:right;">
0.746
</td>
</tr>
<tr>
<td style="text-align:left;">
k=10 k-Nearest Neighbors
</td>
<td style="text-align:right;">
0.756
</td>
<td style="text-align:right;">
0.244
</td>
<td style="text-align:right;">
0.689
</td>
</tr>
<tr>
<td style="text-align:left;">
k=35 k-Nearest Neighbors
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
full Random Forest
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
small Random Forest
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
</tr>
</tbody>
</table>
<div class="figure">
<img src="wine-classification_files/figure-html/knn-roc-curve-1.png" alt="ROC curve of the k-nearest neighbors model where k=10." width="672" />
<p class="caption">
ROC curve of the k-nearest neighbors model where k=10.
</p>
</div>
<p>So with k=10, the k-nearest neighbors model ended up with another
mediocre accuracy rate (0.756). So with an AUC of 0.715, this test is
not very good, but performed similarly to that of the decision tree
model. We can look at different values for k and try to find the best
one to use and then compare the results from that with these. Figure
@ref(fig:finding-best-k) depicts this as a scatterplot of k against
accuracy.</p>
<div class="figure">
<img src="wine-classification_files/figure-html/finding-best-k-1.png" alt="Testing various values of k with the k-nearest neighbors algorithm, and comparing accuracies." width="672" />
<p class="caption">
Testing various values of k with the k-nearest neighbors algorithm, and
comparing accuracies.
</p>
</div>
<p>This is interesting because accuracy seems to increase gradually, hit
a peak, decrease again and slightly increase. We know well that using k
= 1 will result in a very low bias and high variance, and this also
means that we are fitting too closely to the training dataset and
therefore, overfitting. This makes for a bad model that cannot be well
generalized to new data.</p>
<p>Figure @ref(fig:worst-knn) demonstrates this.</p>
<div class="figure">
<img src="wine-classification_files/figure-html/worst-knn-1.png" alt="ROC curve for k-nearest neighbors model where k=1" width="672" />
<p class="caption">
ROC curve for k-nearest neighbors model where k=1
</p>
</div>
<p>Note that the AUC is 0.5, which is the worst possible result since it
is randomly guessing (it has the same chance of a true positive as it
does a false positive). So we think better not to opt for k = 1 and
rather choose some k like 35, which is still decently accurate, and
probably less biased. The confusion matrix for the k = 35 model can be
seen in Table @ref(tab:knn-35-confusion-matrix). As with the prior
models we’ll calculate the accuracy and error rate as well as the AUC,
and plot the ROC curve, which can be seen in Figure @ref(fig:knn35).</p>
<p>The comparison of accuracy rates, error rates, and AUCs is seen in
Table @ref(tab:records-2).</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># library(knn) is loaded</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>new_knn_pred <span class="ot">&lt;-</span> <span class="fu">knn</span>(</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">train =</span> train[, <span class="sc">-</span><span class="dv">9</span>],</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">test =</span> test[, <span class="sc">-</span><span class="dv">9</span>],</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">cl =</span> train<span class="sc">$</span>quality,</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">k =</span> <span class="dv">35</span>,</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">prob =</span> T</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co"># confusion matrix</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>new_knn_conf <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="at">true =</span> test<span class="sc">$</span>quality, <span class="at">pred =</span> new_knn_pred)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co"># accuracy rate</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>new_knn_acc <span class="ot">&lt;-</span> <span class="fu">class_acc</span>(new_knn_conf)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co"># misclassification error rate</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>new_knn_err <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> new_knn_acc</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating the ROC curve for knn</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="co"># library(dplyr) is loaded</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>new_knn_prob <span class="ot">&lt;-</span> <span class="fu">attr</span>(new_knn_pred, <span class="st">&quot;prob&quot;</span>)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>new_knn_prob <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">ifelse</span>(new_knn_pred <span class="sc">==</span> <span class="st">&quot;-1&quot;</span>, </span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>                           <span class="dv">1</span> <span class="sc">-</span> new_knn_prob, new_knn_prob) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>new_knn_roc_pred <span class="ot">&lt;-</span> <span class="fu">prediction</span>(</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">predictions =</span> new_knn_prob,</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>  <span class="at">labels =</span> test<span class="sc">$</span>quality</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>new_knn_roc_perf <span class="ot">&lt;-</span> <span class="fu">performance</span>(new_knn_roc_pred, </span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>                                <span class="at">measure =</span> <span class="st">&quot;tpr&quot;</span>, </span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>                                <span class="at">x.measure =</span> <span class="st">&quot;fpr&quot;</span>)</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Area under the knn curve</span></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>new_knn_auc_perf <span class="ot">&lt;-</span> <span class="fu">performance</span>(new_knn_roc_pred, <span class="at">measure =</span> <span class="st">&quot;auc&quot;</span>)</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>new_knn_auc <span class="ot">&lt;-</span> <span class="fu">round</span>(new_knn_auc_perf<span class="sc">@</span>y.values[[<span class="dv">1</span>]], <span class="dv">3</span>)</span></code></pre></div>
<table>
<caption>
Confusion matrix for 35-nearest neighbors model.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
bad
</th>
<th style="text-align:right;">
good
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
bad
</td>
<td style="text-align:right;">
197
</td>
<td style="text-align:right;">
161
</td>
</tr>
<tr>
<td style="text-align:left;">
good
</td>
<td style="text-align:right;">
84
</td>
<td style="text-align:right;">
558
</td>
</tr>
</tbody>
</table>
<div class="figure">
<img src="wine-classification_files/figure-html/knn35-1.png" alt="ROC curve for k-nearest neighbors model where k=35" width="672" />
<p class="caption">
ROC curve for k-nearest neighbors model where k=35
</p>
</div>
<table>
<caption>
Matrix comparing the accuracy rate, error rate, and AUC for the decision
tree model, the 10-nearest neighbors model, and the 35-nearest neighbors
model.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Accuracy Rate
</th>
<th style="text-align:right;">
Error Rate
</th>
<th style="text-align:right;">
AUC
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Repeated Cross-Validated Decision Tree
</td>
<td style="text-align:right;">
0.739
</td>
<td style="text-align:right;">
0.261
</td>
<td style="text-align:right;">
0.746
</td>
</tr>
<tr>
<td style="text-align:left;">
k=10 k-Nearest Neighbors
</td>
<td style="text-align:right;">
0.756
</td>
<td style="text-align:right;">
0.244
</td>
<td style="text-align:right;">
0.689
</td>
</tr>
<tr>
<td style="text-align:left;">
k=35 k-Nearest Neighbors
</td>
<td style="text-align:right;">
0.755
</td>
<td style="text-align:right;">
0.245
</td>
<td style="text-align:right;">
0.741
</td>
</tr>
<tr>
<td style="text-align:left;">
full Random Forest
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left;">
small Random Forest
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
</tr>
</tbody>
</table>
<p>Looking at the comparison between the models in Table
@ref(tab:records-3), the area under the curve has increased somewhat
while the accuracy has scarcely changed at all, so it could be argued
that the test has improved. What’s more, with a dataset of this
dimensionality, it is most likely better to use more neighbors if one
can, because otherwise you run the risk of overfitting to the training
data (which is why we did not opt for k=1.)</p>
<p>So far when compared to the cross-validated decision tree, k-nearest
neighbors (kNN) seems to be performing similarly in both accuracy and
AUC, so it’s difficult to decide between them. It’s important to note
that kNN is computationally rather expensive and it gets to be very
complex when dealing with datasets with high dimensions (this dataset
has nearly 5000 rows), so we think to rule out k-nearest neighbors when
deciding what the best method of classification is, at least in
comparison to decision trees.</p>
<p>Finally we can move on to the final method of classification, random
forest.</p>
</div>
<div id="random-forest" class="section level2">
<h2>Random Forest</h2>
<p>Random forest is similar to the decision tree method in that it
builds trees, hence the name ‘random forest’. This is an ensemble
learning method which creates a multitude of decision trees, and
outputting the class that occurs most frequently among them. The
advantage that random forest has over decision trees is the element of
randomness which guards against the pitfall of overfitting that decision
trees run into on their own.</p>
<p>As we did with the other models, we’ll calculate the accuracy rate,
error rate, and AUC for this random forest model using all of the
predictors. These metrics as well as the comparison between this model
and the other models can be seen in Table @ref(tab:records-4). The
actual ROC curve is in Figure @ref(fig:full-rf-roc). The confusion
matrix is in Table @ref(tab:rf-confmat). This random forest model will
be built by using the <code>randomForest</code> package in R <span
class="citation">(Breiman et al. 2018)</span>.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="do">### Random Forest</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="co"># using all 8 predictor attributes, on the training set</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">10</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>rf <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">formula =</span> quality <span class="sc">~</span> .,</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> train,</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">mtry =</span> <span class="dv">8</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="co"># predicting on the test set</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>rf_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf, test, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion Matrix</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>rf_conf <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="at">true =</span> test<span class="sc">$</span>quality, <span class="at">pred =</span> rf_pred)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>rf_acc <span class="ot">&lt;-</span> <span class="fu">class_acc</span>(rf_conf)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>rf_err <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> rf_acc</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Building the ROC Curve</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>rf_pred <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">predict</span>(rf, <span class="at">newdata =</span> test, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>))</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>rf_pred_probs <span class="ot">&lt;-</span> rf_pred[, <span class="dv">2</span>]</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>rf_roc_pred <span class="ot">&lt;-</span> <span class="fu">prediction</span>(rf_pred_probs, test<span class="sc">$</span>quality)</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>rf_perf <span class="ot">&lt;-</span> <span class="fu">performance</span>(rf_roc_pred,</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">measure =</span> <span class="st">&quot;tpr&quot;</span>,</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>  <span class="at">x.measure =</span> <span class="st">&quot;fpr&quot;</span></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Area under the curve</span></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>rf_perf2 <span class="ot">&lt;-</span> <span class="fu">performance</span>(rf_roc_pred, <span class="at">measure =</span> <span class="st">&quot;auc&quot;</span>)</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>rf_auc <span class="ot">&lt;-</span> <span class="fu">round</span>(rf_perf2<span class="sc">@</span>y.values[[<span class="dv">1</span>]], <span class="dv">3</span>)</span></code></pre></div>
<table>
<caption>
Confusion matrix for full random forest model.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
bad
</th>
<th style="text-align:right;">
good
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
bad
</td>
<td style="text-align:right;">
253
</td>
<td style="text-align:right;">
105
</td>
</tr>
<tr>
<td style="text-align:left;">
good
</td>
<td style="text-align:right;">
66
</td>
<td style="text-align:right;">
576
</td>
</tr>
</tbody>
</table>
<div class="figure">
<img src="wine-classification_files/figure-html/full-rf-roc-1.png" alt="ROC Curve for full random forest with 8 variables." width="672" />
<p class="caption">
ROC Curve for full random forest with 8 variables.
</p>
</div>
<table>
<caption>
Matrix comparing the accuracy rate, error rate, and AUC for the decision
tre model, the 10-nearest neighbors model, the 35-nearest neighbors
model, and the full random forest.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Accuracy Rate
</th>
<th style="text-align:right;">
Error Rate
</th>
<th style="text-align:right;">
AUC
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Repeated Cross-Validated Decision Tree
</td>
<td style="text-align:right;">
0.739
</td>
<td style="text-align:right;">
0.261
</td>
<td style="text-align:right;">
0.746
</td>
</tr>
<tr>
<td style="text-align:left;">
k=10 k-Nearest Neighbors
</td>
<td style="text-align:right;">
0.756
</td>
<td style="text-align:right;">
0.244
</td>
<td style="text-align:right;">
0.689
</td>
</tr>
<tr>
<td style="text-align:left;">
k=35 k-Nearest Neighbors
</td>
<td style="text-align:right;">
0.755
</td>
<td style="text-align:right;">
0.245
</td>
<td style="text-align:right;">
0.741
</td>
</tr>
<tr>
<td style="text-align:left;">
full Random Forest
</td>
<td style="text-align:right;">
0.829
</td>
<td style="text-align:right;">
0.171
</td>
<td style="text-align:right;">
0.890
</td>
</tr>
<tr>
<td style="text-align:left;">
small Random Forest
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
</tr>
</tbody>
</table>
<p>With an accuracy rate of 0.829, this random forest model is looking
pretty good so far, and it already is more accurate than any method
we’ve tried thus far. The area under the ROC curve for random forest is
0.892, which is also a strong AUC for a classification model and far
above the competing models.</p>
<p>So we see actually that random forest stands head and shoulders above
the other two methods, decision tree and k-nearest neighbors. This is
seen in the fact that the accuracy rate, as well as the AUC, are the
highest. Judging from this, we can assume that random forest would be
the most likely to correctly classify a wine based off of the attributes
and data given.</p>
<div id="a-smaller-random-forest-model" class="section level3">
<h3>A smaller Random Forest model</h3>
<p>We can look at a variable importance plot (See Figure
@ref(fig:varImpPlot)) to see how the variables measure up against each
other in terms of how relevant they are to the classification.</p>
<div class="figure">
<img src="wine-classification_files/figure-html/varImpPlot-1.png" alt="Variable Importance Plot comparing the Gini impurity index" width="672" />
<p class="caption">
Variable Importance Plot comparing the Gini impurity index
</p>
</div>
<p><code>meanDecreaseGini</code> refers to the “mean decrease in node
impurity”. Impurity is a way that the optimal condition of a tree is
determined, and this plot shows how each variable individually affects
the weighted impurity of the tree itself.</p>
<p>This random forest model used all 8 of the predictor variables. This
variable importance plot shows how ‘important’ each variable was in
determining the classification. We can see that, consistent with the
decision tree, that <code>alcohol</code>, <code>volatile.acidity</code>,
and <code>free.sulfur.dioxide</code> are the three most important
predictors. While this random forest model was pretty effective in
utilizing all of the 8 predictors, we can take a look at a model using
only these 3 as well for the sake of comparison.</p>
<p>We have established by now that simpler models have a reduced bias
and complexity, but higher variance and a higher chance of
under-fitting, whereas complex models (such as the full model) have the
opposite issue. The good thing about random forest is that it inherently
accounts for this “Bias-Variance” trade-off by introducing randomness
with bagging (bootstrap aggregating).</p>
<p>The question here is whether or not making the model simpler is
worthwhile, but we can build the simple model and compare their metrics
to find out. This comparison with the prior models can be seen in Table
@ref(tab:records-5). The ROC curve for this model is depicted in Figure
@ref(fig:partial-rf-roc) and the confusion matrix in Table
@ref(tab:partial-rf-confmat).</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">10</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>rf2 <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">formula =</span> quality <span class="sc">~</span> alcohol <span class="sc">+</span> volatile.acidity <span class="sc">+</span> free.sulfur.dioxide,</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> train,</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">mtry =</span> <span class="dv">3</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co"># predicting on the test set</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>rf_pred2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf2, test, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion Matrix</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>rf_conf2 <span class="ot">&lt;-</span> <span class="fu">table</span>(test<span class="sc">$</span>quality, rf_pred2)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>rf_acc2 <span class="ot">&lt;-</span> <span class="fu">class_acc</span>(rf_conf2)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>rf_err2 <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> rf_acc2</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Building the ROC Curve</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>rf_pred2 <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">predict</span>(rf2, test, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>))</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>rf_pred_probs2 <span class="ot">&lt;-</span> rf_pred2[, <span class="dv">2</span>]</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>rf_roc_pred2 <span class="ot">&lt;-</span> <span class="fu">prediction</span>(rf_pred_probs2, test<span class="sc">$</span>quality)</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>rf_perf2 <span class="ot">&lt;-</span> <span class="fu">performance</span>(rf_roc_pred2,</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">measure =</span> <span class="st">&quot;tpr&quot;</span>,</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">x.measure =</span> <span class="st">&quot;fpr&quot;</span></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Area under the curve</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>rf_perf22 <span class="ot">&lt;-</span> <span class="fu">performance</span>(rf_roc_pred2, <span class="at">measure =</span> <span class="st">&quot;auc&quot;</span>)</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>rf_auc2 <span class="ot">&lt;-</span> <span class="fu">round</span>(rf_perf22<span class="sc">@</span>y.values[[<span class="dv">1</span>]], <span class="dv">3</span>)</span></code></pre></div>
<table>
<caption>
Confusion matrix for smaller random forest model.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
bad
</th>
<th style="text-align:right;">
good
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
bad
</td>
<td style="text-align:right;">
228
</td>
<td style="text-align:right;">
130
</td>
</tr>
<tr>
<td style="text-align:left;">
good
</td>
<td style="text-align:right;">
72
</td>
<td style="text-align:right;">
570
</td>
</tr>
</tbody>
</table>
<div class="figure">
<img src="wine-classification_files/figure-html/partial-rf-roc-1.png" alt="ROC curve for the random forest model using predictors 'free sulfur dioxide', 'volatile acidity', and 'alcohol'." width="672" />
<p class="caption">
ROC curve for the random forest model using predictors ‘free sulfur
dioxide’, ‘volatile acidity’, and ‘alcohol’.
</p>
</div>
<table>
<caption>
The final matrix comparing the accuracy rates, error rates, and AUCs for
all of the models.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Accuracy Rate
</th>
<th style="text-align:right;">
Error Rate
</th>
<th style="text-align:right;">
AUC
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Repeated Cross-Validated Decision Tree
</td>
<td style="text-align:right;">
0.739
</td>
<td style="text-align:right;">
0.261
</td>
<td style="text-align:right;">
0.746
</td>
</tr>
<tr>
<td style="text-align:left;">
k=10 k-Nearest Neighbors
</td>
<td style="text-align:right;">
0.756
</td>
<td style="text-align:right;">
0.244
</td>
<td style="text-align:right;">
0.689
</td>
</tr>
<tr>
<td style="text-align:left;">
k=35 k-Nearest Neighbors
</td>
<td style="text-align:right;">
0.755
</td>
<td style="text-align:right;">
0.245
</td>
<td style="text-align:right;">
0.741
</td>
</tr>
<tr>
<td style="text-align:left;">
full Random Forest
</td>
<td style="text-align:right;">
0.829
</td>
<td style="text-align:right;">
0.171
</td>
<td style="text-align:right;">
0.890
</td>
</tr>
<tr>
<td style="text-align:left;">
small Random Forest
</td>
<td style="text-align:right;">
0.798
</td>
<td style="text-align:right;">
0.202
</td>
<td style="text-align:right;">
0.854
</td>
</tr>
</tbody>
</table>
<p>The accuracy rate has actually decreased from 0.829 to 0.798, as well
as the area under the curve from 0.892 to 0.854, but the model remains
relatively strong, at least compared to the others. We’re managed to
actually preserve the strength of the model, both in relation to the
tree and k-nearest neighbor methods, but also relative to the original
application of random forest with all of the predictors.</p>
<p>As such, we can opt to utilize this much smaller model for
classification instead if we are concerned about complexity and bias.
Having said that, because of the randomization introduced in the random
forest, it is inherently more robust so sub-setting in this manner may
not even be unnecessary.</p>
</div>
</div>
</div>
<div id="results" class="section level1">
<h1>Results</h1>
<p>Now that we have accuracy and AUC metrics for all of the models, we
can compare them on a plot to judge which is the best model. See Figure
@ref(fig:final-comparison).</p>
<div class="figure">
<img src="wine-classification_files/figure-html/final-comparison-1.png" alt="Scatterplot comparing AUC and Accuracy Rate of all models." width="672" />
<p class="caption">
Scatterplot comparing AUC and Accuracy Rate of all models.
</p>
</div>
<p>Looking at this plot of accuracy rate against AUC, it’s quite clear
that the largest random forest model is the best one, even after
downsizing the model to a subset of the predictors. With that said, the
smaller random forest model still comes out much stronger than the
competition in comparison.</p>
</div>
<div id="discussion" class="section level1">
<h1>Discussion</h1>
<p>So judging from all of our findings, we have seen that in this case,
random forest is the best algorithm (out of the three we’ve compared)
for classifying this wine dataset. So we have answered the question of
what among these three classification algorithms is truly the best.</p>
<p>The decision tree algorithm is useful but ultimately, random forest
is superior version of it since it aggregates many decision trees to
create an optimized model that is not susceptible to overfitting. When
it comes to interpretability however, a decision tree is preferred. When
using a decision tree however it is important to use cross-validation
(ideally repeatedly) to ensure the tree does not overfit while retaining
interpretability.</p>
<p>Compared to decision trees, the k-nearest neighbor algorithm has a
slightly greater accuracy rate but a worse AUC. The decision tree method
did however help to narrow down the three most relevant attributes:
<code>alcohol</code>, <code>volatile.acidity</code>, and
<code>free.sulfur.dioxide</code>. This finding was consistent with when
we took a look at the most important variables in the random forest
model.</p>
<p>We were able to apply this subset of attributes to the random forest
algorithm and come out with a strong model that only utilizes a few
independent variables in order to classify at a high success rate. This
lends strength to the argument that these three variables are the most
relevant when it comes to determining the content of a good wine.</p>
<p>As far as what these variables’ importance is in reality, is that
sulfur dioxide is crucial for killing bacteria in wine when creating it.
On the other hand, volatile acidity is an undesired trait in wine that
affects flavor, that can be caused by such bacteria. So it makes sense
that wine that is high in sulfur dioxide, and low in volatile acidity,
is considered good.</p>
<p>The pending questions that remain are, did we overfit or underfit to
the training data when testing these different classification methods?
It is also worth determining exactly the threshold for the amounts of
these variables such as <code>alcohol</code>, for example finding the
optimal amount of alcohol content to create a good wine.</p>
<p>We would also like to delve more into how best to select some k for
kNN that maintains a high level of accuracy while also having a balance
between bias and variance without either over or underfitting. We would
also posit a similar question for the number of nodes in a decision
tree. Finally, is dropping variables in random forest really necessary,
if the randomization inherent in it already accounts for
overfitting?</p>
<p>If we can only compare models that utilize the same set of
predictors, then we should look at the pruned classification tree
against the random forest model utilizing the same attributes. We see
even there that the random forest model is superior.</p>
<p>In conclusion we have found that random forest is best for binary
classification and that alcohol, volatile acidity, and free sulfur
dioxide are the most important predictors when attempting to classify a
good wine.</p>
<div style="page-break-after: always;"></div>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-R-randomForest" class="csl-entry">
Breiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2018.
<em>randomForest: Breiman and Cutler’s Random Forests for Classification
and Regression</em>. <a
href="https://www.stat.berkeley.edu/~breiman/RandomForests/">https://www.stat.berkeley.edu/~breiman/RandomForests/</a>.
</div>
<div id="ref-R-caret" class="csl-entry">
Kuhn, Max. 2020. <em>Caret: Classification and Regression Training</em>.
<a
href="https://github.com/topepo/caret/">https://github.com/topepo/caret/</a>.
</div>
<div id="ref-R-class" class="csl-entry">
Ripley, Brian. 2020. <em>Class: Functions for Classification</em>. <a
href="http://www.stats.ox.ac.uk/pub/MASS4/">http://www.stats.ox.ac.uk/pub/MASS4/</a>.
</div>
<div id="ref-R-ROCR" class="csl-entry">
Sing, Tobias, Oliver Sander, Niko Beerenwinkel, and Thomas Lengauer.
2020. <em>ROCR: Visualizing the Performance of Scoring Classifiers</em>.
<a
href="http://ipa-tys.github.io/ROCR/">http://ipa-tys.github.io/ROCR/</a>.
</div>
<div id="ref-tan_introduction_2019" class="csl-entry">
Tan, Pang-Ning, Michael Steinbach, Anuj Karpatne, and Vipin Kumar. 2019.
<em>Introduction to Data Mining</em>. Second edition. NY NY: Pearson.
</div>
<div id="ref-R-rpart" class="csl-entry">
Therneau, Terry, and Beth Atkinson. 2019. <em>Rpart: Recursive
Partitioning and Regression Trees</em>. <a
href="https://CRAN.R-project.org/package=rpart">https://CRAN.R-project.org/package=rpart</a>.
</div>
<div id="ref-noauthor_uci_nodate" class="csl-entry">
<span>“<span>UCI</span> <span>Machine</span> <span>Learning</span>
<span>Repository</span>.”</span> n.d. Accessed November 1, 2020. <a
href="https://archive.ics.uci.edu/ml/index.php">https://archive.ics.uci.edu/ml/index.php</a>.
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
